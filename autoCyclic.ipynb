{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLAb_-riTz0i"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Wf2udUrhYzQ"
      },
      "source": [
        "# Deep Transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqbgp_VZhPjA"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pik-ValOhq8U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, einsum\n",
        "from torch.nn.modules.linear import Linear\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IryxH6ZFrpLo"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OCkFTnihw9k"
      },
      "source": [
        "Full Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bzUtBtG7hwZe"
      },
      "outputs": [],
      "source": [
        "def full_attention(query, key, value, causal=False, dropout=0.0):\n",
        "    device = key.device\n",
        "    B_k, h_k, n_k, d_k = key.shape\n",
        "    B_q, h_q, n_q, d_q = query.shape\n",
        "\n",
        "    scale = einsum(\"bhqd,bhkd->bhqk\", query, key)/math.sqrt(d_k)\n",
        "\n",
        "    if causal:\n",
        "        ones = torch.ones(B_k, h_k, n_q, n_k).to(device)\n",
        "        mask = torch.tril(ones)\n",
        "        scale = scale.masked_fill(mask == 0, -1e9)\n",
        "    atn = F.softmax(scale, dim=-1)\n",
        "    if dropout is not None:\n",
        "        atn = F.dropout(atn, p=dropout)\n",
        "    out = einsum(\"bhqk,bhkd->bhqd\", atn, value)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SG2zO9xrN9CA"
      },
      "outputs": [],
      "source": [
        "def to_eachhead(x, head_num, split_num=3):\n",
        "    B, n, pre_d = x.shape\n",
        "    new_d = pre_d//split_num\n",
        "    assert pre_d%split_num == 0, f\"have to be multiple of {split_num}\"\n",
        "    assert new_d%head_num == 0, \"dim must be divided by head_num\"\n",
        "\n",
        "    tpl = torch.chunk(x, split_num, dim=2)\n",
        "    out = []\n",
        "    for t in tpl:\n",
        "        out.append(t.reshape(B, n, head_num, new_d//head_num).transpose(1,2))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MBKXBwhSOFnS"
      },
      "outputs": [],
      "source": [
        "def concat_head(x):\n",
        "    B, h, n, _d = x.shape\n",
        "    out = x.transpose(1,2).reshape(B, n, _d*h)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtedPTrxiDyG"
      },
      "source": [
        "Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NhTmV24Zg8tI"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, #dropout: float = 0.1,\n",
        "                 max_len: int = 100):\n",
        "        super().__init__()\n",
        "        # self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.squeeze(1))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x + self.pe[:x.size(1)]\n",
        "        # return self.dropout(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKrmu6OBP8G9"
      },
      "source": [
        "Pre-layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OiJ8GvefQAWZ"
      },
      "outputs": [],
      "source": [
        "class PreLayer(nn.Module):\n",
        "    def __init__(self, hid, d_model, drop_out=0.0, in_dim=1):\n",
        "        super().__init__()\n",
        "        # self.linear = nn.Linear(in_dim, d_model)\n",
        "        self.linear1 = nn.Linear(in_dim, hid, bias=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hid, d_model, bias=True)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # out = self.linear(x)\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i85xI01ZP-r-"
      },
      "source": [
        "Post-layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v3JWCaq2QGV7"
      },
      "outputs": [],
      "source": [
        "class PostLayer(nn.Module):\n",
        "    def __init__(self, dim, vocab_num, hid_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "        # self.linear = nn.Linear(dim, vocab_num)\n",
        "        self.linear1 = nn.Linear(dim, hid_dim, bias=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hid_dim, vocab_num, bias=True)\n",
        "    def forward(self,x):\n",
        "        # out = self.linear(x)\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5elRhXaaQhF3"
      },
      "source": [
        "Multi-head Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRR-8kZlhz6e"
      },
      "source": [
        "1) Multi-head Self Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IQemVp6yh2Jc"
      },
      "outputs": [],
      "source": [
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, dim, head_num):\n",
        "        super().__init__()\n",
        "        self.to_qvk = nn.Linear(dim, dim*3)\n",
        "        self.make_head = partial(to_eachhead, head_num=head_num, split_num=3)\n",
        "        self.mhsa = full_attention\n",
        "\n",
        "    def forward(self, x):\n",
        "        qvk = self.to_qvk(x)\n",
        "        q, v, k = self.make_head(qvk)\n",
        "        out = self.mhsa(q, k, v)\n",
        "        out = concat_head(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGcwyuxhQyPV"
      },
      "source": [
        "2) Multi-head Causal Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "96fRrPGOQ08N"
      },
      "outputs": [],
      "source": [
        "class MultiHeadCausalAttention(nn.Module):\n",
        "    def __init__(self, dim, head_num):\n",
        "        super().__init__()\n",
        "        self.to_qvk = nn.Linear(dim, dim*3)\n",
        "        self.make_head = partial(to_eachhead, head_num=head_num, split_num=3)\n",
        "        self.mhca = partial(full_attention, causal=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        qvk = self.to_qvk(x)\n",
        "        q, v, k = self.make_head(qvk)\n",
        "        out = self.mhca(q, k, v)\n",
        "        out = concat_head(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2tUHWZnQ3mQ"
      },
      "source": [
        "3) Multi-head Source Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mptn46JXQ4AC"
      },
      "outputs": [],
      "source": [
        "class MultiHeadSourceAttention(nn.Module):\n",
        "    def __init__(self, dim, head_num):\n",
        "        super().__init__()\n",
        "        self.to_kv = nn.Linear(dim, dim*2)\n",
        "        self.to_q = nn.Linear(dim, dim)\n",
        "        self.make_head_kv = partial(to_eachhead, head_num=head_num, split_num=2)\n",
        "        self.make_head_q = partial(to_eachhead, head_num=head_num, split_num=1)\n",
        "        self.mhsa = full_attention\n",
        "\n",
        "    def forward(self, x, memory):\n",
        "        mem = self.to_kv(memory)\n",
        "        x = self.to_q(x)\n",
        "        k, v = self.make_head_kv(mem)\n",
        "        q = self.make_head_q(x)[0]\n",
        "        out = self.mhsa(q, k, v)\n",
        "        out = concat_head(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn_j1AYOh8qI"
      },
      "source": [
        "Feed Fordward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TE57qHUpiAnL"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(dim, hid_dim, bias=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hid_dim, dim, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0Loy-Y6ibjG"
      },
      "source": [
        "Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Yoepwo5WiuKP"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, dim, head_num, ff_hidnum, dropout_ratio, norm_first=False):\n",
        "        super().__init__()\n",
        "        self.dor = dropout_ratio\n",
        "        self.mhsa = MultiHeadSelfAttention(dim, head_num)\n",
        "        self.ln1 = nn.LayerNorm(dim)\n",
        "        self.ff = FeedForward(dim, ff_hidnum)\n",
        "        self.ln2 = nn.LayerNorm(dim)\n",
        "        self.norm_first = norm_first\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = torch.clone(x)\n",
        "\n",
        "        if self.norm_first:\n",
        "          out = self.ln1(x)\n",
        "          out = self.mhsa(out)\n",
        "          out = F.dropout(out, p=self.dor) + res\n",
        "\n",
        "          res = torch.clone(out)\n",
        "          out = self.ln2(out)\n",
        "          out = self.ff(out)\n",
        "          out = F.dropout(out, p=self.dor) + res\n",
        "        else:\n",
        "          out = self.mhsa(x)\n",
        "          out = F.dropout(out, p=self.dor) + res\n",
        "          out = self.ln1(out)\n",
        "\n",
        "          res = torch.clone(out)\n",
        "          out = self.ff(out)\n",
        "          out = F.dropout(out, p=self.dor) + res\n",
        "          out = self.ln2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z-HJWJ_nffA7"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, depth, dim, head_num, ff_hidnum=2048, dropout_ratio=0.2, norm_first=False):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([EncoderLayer(dim, head_num, ff_hidnum, dropout_ratio, norm_first) for i in range(depth)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXnhQ17bivln"
      },
      "source": [
        "Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ad789UZyi0GJ"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, dim, head_num, ff_hidnum, dropout_ratio, norm_first=False):\n",
        "        super().__init__()\n",
        "        self.dor = dropout_ratio\n",
        "        self.mhca = MultiHeadCausalAttention(dim, head_num)\n",
        "        self.ln1 = nn.LayerNorm(dim)\n",
        "        self.mhsa = MultiHeadSourceAttention(dim, head_num)\n",
        "        self.ln2 = nn.LayerNorm(dim)\n",
        "        self.ff = FeedForward(dim, ff_hidnum)\n",
        "        self.ln3 = nn.LayerNorm(dim)\n",
        "        self.norm_first = norm_first\n",
        "\n",
        "    def forward(self, x, memory):\n",
        "        res = torch.clone(x)\n",
        "\n",
        "        if self.norm_first:\n",
        "          out = self.ln1(x)\n",
        "          out = self.mhca(out)\n",
        "          out = F.dropout(out, p=self.dor) + res\n",
        "\n",
        "          res = torch.clone(out)\n",
        "          out = self.ln2(out)\n",
        "          out = self.mhsa(out, memory)\n",
        "          out = F.dropout(out, p=self.dor) + res\n",
        "\n",
        "          res = torch.clone(out)\n",
        "          out = self.ln3(out)\n",
        "          out = self.ff(out)\n",
        "          out = F.dropout(out, p=self.dor) + res\n",
        "\n",
        "        else:\n",
        "          out = self.mhca(x)\n",
        "          out = F.dropout(out, p=self.dor) + res\n",
        "          out = self.ln1(out)\n",
        "\n",
        "          res = torch.clone(out)\n",
        "          out = self.mhsa(out, memory)\n",
        "          out = F.dropout(out, p=self.dor) + res\n",
        "          out = self.ln2(out)\n",
        "\n",
        "          res = torch.clone(out)\n",
        "          out = self.ff(out)\n",
        "          out = F.dropout(out, p=self.dor) + res\n",
        "          out = self.ln3(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "F4w_yvb_ffA8"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, depth, dim, head_num, ff_hidnum, dropout_ratio=0.2, norm_first=False):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([DecoderLayer(dim, head_num, ff_hidnum, dropout_ratio, norm_first) for i in range(depth)])\n",
        "\n",
        "    def forward(self, x, memory):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x-lKLAljNGT"
      },
      "source": [
        "Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EiUSMgetjOhX"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, device, d_model, in_dim, N_enc, N_dec, h_enc, h_dec, ff_hidnum, hid_pre, hid_post, dropout_pre, dropout_post, dropout_model, norm_first=False):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.x_pre = PreLayer(hid_pre, d_model, dropout_pre, in_dim)\n",
        "        self.y_pre = PreLayer(hid_pre, d_model, dropout_pre, in_dim)\n",
        "        self.pos = PositionalEncoding(d_model)\n",
        "        self.enc = Encoder(N_enc,d_model, h_enc, ff_hidnum, dropout_model, norm_first)\n",
        "        self.dec = Decoder(N_dec,d_model, h_dec, ff_hidnum, dropout_model, norm_first)\n",
        "        self.post = PostLayer(d_model, 1, hid_post, dropout_post)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x_emb = self.x_pre(x)\n",
        "        y_emb = self.y_pre(y)\n",
        "        x_emb_pos = self.pos(x_emb)\n",
        "        y_emb_pos = self.pos(y_emb)\n",
        "        memory = self.enc(x_emb_pos)\n",
        "        out = self.dec(y_emb_pos, memory)\n",
        "        out = self.post(out)\n",
        "        out = out.squeeze(-1)\n",
        "        return out\n",
        "\n",
        "    def generate(self, x, forcast_step, y_start,multivariate=False):\n",
        "        device = x.device\n",
        "        x = x.to(device)\n",
        "        B, N, D = x.shape\n",
        "        x = self.x_pre(x) \n",
        "        x = self.pos(x)\n",
        "        z = self.enc(x) \n",
        "        y = y_start\n",
        "        for i in range(forcast_step):\n",
        "            y_pred = self.y_pre(y)\n",
        "            y_pred = self.pos(y_pred)\n",
        "            y_pred = self.dec(y_pred, z)\n",
        "            y_pred = self.post(y_pred)\n",
        "            if multivariate:\n",
        "                y = torch.cat([y, y_pred[:,[-1],:]], dim=2)\n",
        "            else:\n",
        "                y = torch.cat([y, y_pred[:,[-1],:]], dim=1)\n",
        "        y_pred = y_pred.squeeze(-1)\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXfmpn8JnJVk"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ex8jTggGnLHl"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, input_step, predict_step):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.predict_step = predict_step\n",
        "        self.input_step = input_step\n",
        "        self.start_max = self.data.shape[0] - (self.predict_step + self.input_step) + 1\n",
        "        self.datalen = self.start_max\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.datalen\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = idx % self.start_max\n",
        "        predict_idx = start_idx + self.input_step\n",
        "        end_idx = predict_idx + self.predict_step\n",
        "\n",
        "        x = self.data[start_idx:predict_idx, :]\n",
        "        y = self.data[predict_idx-1:end_idx-1, :]\n",
        "        tgt = self.data[predict_idx:end_idx, :]\n",
        "\n",
        "        x = torch.from_numpy(x)\n",
        "        y = torch.from_numpy(y)\n",
        "        tgt = torch.from_numpy(tgt)\n",
        "\n",
        "        return x, y, tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rnHFWhIq_G9B"
      },
      "outputs": [],
      "source": [
        "# data_path = 'https://data.covid19.go.id/public/api/update.json'\n",
        "# data_path = 'update_22-3-2022.json'\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def load_data(data_path, dataset_len=None, test_size=30,multivariate=False):\n",
        "    # data = requests.get(data_path).json() if from_api else pd.read_json(data_path)\n",
        "\n",
        "    # data = pd.DataFrame(data['update']['harian'])[['key','jumlah_positif']]\n",
        "    # data.key = pd.to_datetime(data.key, unit='ms')\n",
        "\n",
        "    # data=pd.read_csv(data_path)\n",
        "    # data=data[[\"V1\",\"V2\"]]\n",
        "    # data = data.set_index('V1')\n",
        "\n",
        "    # ETTm2\n",
        "    data=pd.read_csv(data_path)\n",
        "    data=data[[\"date\",\"OT\"]]\n",
        "    data = data.set_index('date')\n",
        "\n",
        "    # Turbine Dataset\n",
        "    # data=pd.read_csv(data_path)\n",
        "    # data = data.rename(columns={data.columns[0]: 'Date'}) \n",
        "    # data=data.dropna(subset=[\"ActivePower\",\"WindSpeed\"])\n",
        "    # # data=data[[\"Date\",\"ActivePower\",\"WindSpeed\"]]\n",
        "    # data=data[[\"Date\",\"ActivePower\"]]\n",
        "    # data = data.set_index('Date')\n",
        "\n",
        "\n",
        "    data_len = data.shape[0]\n",
        "    if multivariate:\n",
        "        numpy_use = data.to_numpy()\n",
        "        original_data = data\n",
        "        from sklearn.preprocessing import MinMaxScaler\n",
        "        numpy_use_jii = data['OT'].to_numpy()\n",
        "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "        numpy_use_jii = scaler.fit_transform(numpy_use_jii.reshape(-1,1))\n",
        "        scaler_all = MinMaxScaler(feature_range=(-1, 1)) \n",
        "        numpy_use = scaler_all.fit_transform(numpy_use)\n",
        "        \n",
        "        train_val, test_only = numpy_use[:data_len - test_size,:], numpy_use[data_len - test_size:,:]\n",
        "        train_num = data_len//10 * 8\n",
        "        train_data = train_val[:train_num].astype(\"float32\")\n",
        "        val_data = train_val[train_num:].astype(\"float32\")\n",
        "        test_data = test_only.astype(\"float32\")\n",
        "        return train_data, val_data, test_data, scaler, original_data\n",
        "    else:\n",
        "        numpy_use = data['OT'].to_numpy()\n",
        "        original_data = data[\"OT\"]\n",
        "        from sklearn.preprocessing import MinMaxScaler\n",
        "        scaler = MinMaxScaler(feature_range=(-1, 1)) \n",
        "        numpy_use = scaler.fit_transform(numpy_use.reshape(-1,1))\n",
        "        \n",
        "        train_val, test_only = numpy_use[:numpy_use.size - test_size], numpy_use[numpy_use.size - test_size:]\n",
        "        train_num = data_len//10 * 8\n",
        "        train_data = train_val[:train_num].astype(\"float32\")\n",
        "        val_data = train_val[train_num:].astype(\"float32\")\n",
        "        test_data = test_only.astype(\"float32\")\n",
        "        return train_data, val_data, test_data, scaler, original_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "31h68SUS9RXp"
      },
      "outputs": [],
      "source": [
        "def make_dataloader(train_data, val_data, test_data, input_step, predict_step, batch_size, shuffle_train=True, shuffle_val=False):\n",
        "    train_set = Dataset(train_data, input_step, predict_step)\n",
        "    val_set = Dataset(val_data, input_step, predict_step)\n",
        "    test_set = Dataset(test_data, input_step, predict_step)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size, shuffle=shuffle_train)\n",
        "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=shuffle_val)\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w06YpJZsjhC1"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oUlzDFPFWJo"
      },
      "source": [
        "Training Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sp15c4v5nBPP"
      },
      "outputs": [],
      "source": [
        "def lr_func(step, d_model):\n",
        "    warmup_steps = 5000\n",
        "    step_term = min(step**0.5, step*warmup_steps**(-1.5))\n",
        "    return d_model**0.5 * step_term"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SEU5QlGno7Fe"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def fix_seed(seed):\n",
        "    # random\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bU8xeHRaVcOY"
      },
      "outputs": [],
      "source": [
        "## Calculate MSE eval\n",
        "def check_data(device, test_loader, net, criterion):\n",
        "    net.eval()\n",
        "    loss_log = []\n",
        "    for iter, (x, y, tgt) in enumerate(test_loader):\n",
        "        x, y, tgt = x.to(device), y.to(device), tgt.to(device)\n",
        "        tgt = tgt[:,:,0]\n",
        "\n",
        "        out = net(x, y)\n",
        "\n",
        "        loss = criterion(out, tgt)\n",
        "        loss_log.append(loss.item())\n",
        "\n",
        "    return sum(loss_log)/len(loss_log)# MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {
        "id": "QALsb7NgGa7j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YfvsfI1po23t"
      },
      "outputs": [],
      "source": [
        "torch.set_printoptions(precision=5, sci_mode=False)\n",
        "np.set_printoptions(precision=5, suppress=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ9GnGwskDQu"
      },
      "source": [
        "Hyper-parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BQSrVcnikGNC"
      },
      "outputs": [],
      "source": [
        "input_step = 4\n",
        "predict_step = 1\n",
        "d_model = 64\n",
        "batch_size = 1114\n",
        "max_epoch = 1\n",
        "in_dim = 1\n",
        "N_enc = 1\n",
        "N_dec = 1\n",
        "h_enc = 1\n",
        "h_dec = 1\n",
        "ff_hidnum = 100\n",
        "hid_pre = 100\n",
        "hid_post =100\n",
        "dropout_pre = 0\n",
        "dropout_post = 0\n",
        "dropout_model = 0\n",
        "save_each = 10\n",
        "multi=False\n",
        "norm_first = False # default = False (Post-LN)\n",
        "# dbg = args.debug\n",
        "model_path = 'content/model/'\n",
        "test_result_path = 'content/test_result_path/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "C3Hd_iTWFjH6"
      },
      "outputs": [],
      "source": [
        "# dir_list = [\"/content/model/\",\"/content/test_result_path/\"]\n",
        "\n",
        "# for dir in dir_list:\n",
        "#   if os.path.isdir(dir) != True:\n",
        "#     os.mkdir(dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBYIHpPmjYmz"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvTeaHQ5BAhc"
      },
      "outputs": [],
      "source": [
        "train, val, test, scaler, original = load_data(\"Data/ETTm2.csv\", test_size=120,multivariate=multi)\n",
        "# train, val, test, scaler, original = load_data('update 12-05-2022.json', from_api=False,\n",
        "#                                                          dataset_len=750, test_size=60)#input_step+predict_step+60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 410,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqJtpGULQmxD",
        "outputId": "320303bd-4713-45f3-c6c3-dc7232bf8314"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((75544, 1), (18772, 1), (120, 1))"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape, val.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 411,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x1WUTVNT_jB",
        "outputId": "37dd2198-dfd2-4312-f604-ae98e46eca91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "94436"
            ]
          },
          "execution_count": 411,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.size + val.size + test.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 412,
      "metadata": {
        "id": "qUZu79mxBlnb"
      },
      "outputs": [],
      "source": [
        "train_loader, val_loader, test_loader = make_dataloader(train, val, test, input_step, predict_step, batch_size, shuffle_train=False, shuffle_val=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Manual Run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AutoCyclic Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 413,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import pytorch_forecasting\n",
        "\n",
        "class AutoCyclicLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, base_lr, max_lr, step_size, last_epoch=-1):\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.data = None\n",
        "        super(AutoCyclicLR, self).__init__(optimizer, last_epoch) \n",
        "    def get_lr(self):\n",
        "        cycle = math.floor(1 + self.last_epoch / (2 * self.step_size))\n",
        "        x = abs(self.last_epoch / self.step_size - 2 * cycle + 1)\n",
        "        lr = [self.base_lr + (self.max_lr - self.base_lr) * (1 + math.cos(math.pi * x)) / 2 * (1 + self.get_batch_variance()) for _ in self.base_lrs]\n",
        "        return lr\n",
        "    def get_batch_variance(self):\n",
        "        # AutoCorrelation+sigmoid\n",
        "        if self.data is None:\n",
        "            return 1\n",
        "        step_var=[]\n",
        "        for items in self.data:\n",
        "            SGLayer = nn.Sigmoid()\n",
        "            output=pytorch_forecasting.autocorrelation(items)\n",
        "            output=torch.nan_to_num(output, nan=0)\n",
        "            output=SGLayer(output)\n",
        "            step_var.append(torch.var(output))\n",
        "        tensor_batch_step_var = torch.tensor(step_var)\n",
        "        mean_step=torch.mean(tensor_batch_step_var)\n",
        "        batch_variance = mean_step.numpy()\n",
        "        return batch_variance    \n",
        "    def set_batch_data(self, data):\n",
        "        self.data = data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 420,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = Transformer(device, d_model, in_dim, N_enc, N_dec, h_enc, h_dec, ff_hidnum, hid_pre, hid_post, dropout_pre, dropout_post, dropout_model, norm_first)\n",
        "net = net.to(device)\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "\n",
        "train_loss_log = []\n",
        "val_loss_log = []\n",
        "\n",
        "best_train_loss = np.inf\n",
        "best_val_loss = np.inf\n",
        "best_both_loss = (np.inf, np.inf)\n",
        "best_train_epoch = 0\n",
        "best_val_epoch = 0\n",
        "best_both_epoch = 0\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# buatcyclic \n",
        "base_lr=0.0002782559402207126\n",
        "max_lr_multiplier=7\n",
        "cycle_size=25\n",
        "lrs=[]\n",
        "bvs=[]\n",
        "\n",
        "max_iteration = 0\n",
        "for epoch in range(max_epoch):\n",
        "  # scheduler = CosineCyclicLR(optimizer, base_lr=base_lr,max_lr=(base_lr*max_lr_multiplier), step_size=cycle_size)\n",
        "  scheduler = AutoCyclicLR(optimizer, base_lr=base_lr, max_lr=(base_lr*max_lr_multiplier), step_size=cycle_size)\n",
        "  tgt_log_train = np.zeros((1,predict_step))\n",
        "  pred_log_train = np.zeros((1,predict_step))\n",
        "\n",
        "  for iter, (x, y, tgt) in enumerate(train_loader):\n",
        "    x, y, tgt = x.to(device), y.to(device), tgt.to(device)\n",
        "    \n",
        "    tgt = tgt[:,:,0]\n",
        "    net.train()\n",
        "    scheduler.set_batch_data(x)  \n",
        "      \n",
        "    out = net(x, y)\n",
        "    loss = criterion(out, tgt)\n",
        "            \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    lrs.append(scheduler.get_last_lr())\n",
        "    bvs.append(scheduler.get_batch_variance())\n",
        "      \n",
        "    out_npy = out.to('cpu').detach().numpy().copy()\n",
        "    tgt_npy = tgt.to('cpu').detach().numpy().copy()\n",
        "\n",
        "    pred_log_train = np.concatenate([pred_log_train, out_npy], axis=0)\n",
        "    tgt_log_train = np.concatenate([tgt_log_train, tgt_npy], axis=0)   \n",
        "  break\n",
        "\n",
        "  if epoch == 0:\n",
        "    max_iteration = iter + 1\n",
        "  train_loss_log.append(loss.item())      \n",
        "  val_loss = check_data(device, val_loader, net, criterion)\n",
        "  val_loss_log.append(val_loss)# MSE\n",
        "  print(\"epoch : {}, MSE loss : {}, RMSE loss : {}\".format(epoch, loss.item(), torch.sqrt(loss).item()))\n",
        "  # print(\"*************validation******************\")\n",
        "  print(\"val_loss : {}, rmse : {}\\n\".format(val_loss, math.sqrt(val_loss)))\n",
        "  \n",
        "  # save low train loss model\n",
        "  if loss < best_train_loss:\n",
        "    best_train_loss = loss\n",
        "    best_train_epoch = epoch\n",
        "    torch.save(net.state_dict(), os.path.join(model_path, \"best_train_loss_model.model\"))\n",
        "\n",
        "  # save low val loss model\n",
        "  if val_loss < best_val_loss:\n",
        "    best_val_loss = val_loss\n",
        "    best_val_epoch = epoch\n",
        "    torch.save(net.state_dict(), os.path.join(model_path, \"best_val_loss_model.model\"))\n",
        "    \n",
        "  # save both loss model\n",
        "  if loss < best_train_loss and val_loss < best_val_loss:\n",
        "    best_both_loss = (loss, val_loss)\n",
        "    best_both_epoch = epoch\n",
        "    torch.save(net.state_dict(), os.path.join(model_path, \"best_both_loss_model.model\"))\n",
        "\n",
        "  # save model\n",
        "  if epoch % save_each == 0 or epoch == max_epoch - 1:\n",
        "    torch.save(net.state_dict(), os.path.join(model_path, '{}_epoch.model'.format(epoch)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loss_np = np.array(train_loss_log)\n",
        "val_loss_np = np.array(val_loss_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 0, inf)"
            ]
          },
          "execution_count": 254,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_train_epoch, best_val_epoch,best_val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_plot = best_val_epoch-10 if best_val_epoch >= 10 else 0\n",
        "max_plot = best_val_epoch+10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_dataloader(data, input_step, predict_step, batch_size=1):\n",
        "    dataset = Dataset(data, input_step, predict_step)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "    return dataset, dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.set_printoptions(precision=5, sci_mode=False)\n",
        "np.set_printoptions(precision=5, suppress=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set, test_loader = make_dataloader(test, input_step, predict_step, batch_size=600)\n",
        "all_data = test_set.data[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(120, 1)"
            ]
          },
          "execution_count": 260,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "execution_count": 261,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "epoch_num = best_val_epoch\n",
        "print(epoch_num)\n",
        "par_path = os.path.join(model_path, \"best_val_loss_model.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = Transformer(device, d_model, in_dim, N_enc, N_dec, h_enc, h_dec, ff_hidnum, hid_pre, hid_post, dropout_pre, dropout_post, dropout_model, norm_first)\n",
        "    \n",
        "# load parameter\n",
        "if device == torch.device(\"cpu\"):\n",
        "  net.load_state_dict(torch.load(par_path, map_location=torch.device(\"cpu\")))\n",
        "else:\n",
        "  net.load_state_dict(torch.load(par_path,map_location=torch.device(device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "net.eval()\n",
        "\n",
        "pred_list = np.zeros((1, predict_step))\n",
        "for iter, (x, y, tgt) in enumerate(test_loader):\n",
        "    tgt = tgt[:,:,0]\n",
        "\n",
        "    out = net.generate(x, tgt.shape[1], y[:,[0],:],multi)\n",
        "    out = out.to('cpu').detach().numpy().copy()\n",
        "\n",
        "    pred_list = np.concatenate([pred_list, out], axis=0)\n",
        "\n",
        "pred_list = pred_list[1:]\n",
        "D = []\n",
        "for i in range(predict_step):\n",
        "    tmp = np.concatenate([all_data[:(input_step+i)], pred_list[:,i], all_data[(all_data.shape[0]-(predict_step - (i + 1))):]])\n",
        "    D.append(tmp)\n",
        "\n",
        "for step_num, tmp_data in enumerate(D):\n",
        "    n = step_num + 1\n",
        "\n",
        "    np.save(os.path.join(test_result_path, \"pred{}_epoch{}\".format(n, epoch_num)), pred_list[:,[step_num]])\n",
        "    np.save(os.path.join(test_result_path, \"tgt{}_epoch{}\".format(n, epoch_num)), tgt[:,[step_num]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data_denorm = np.round(scaler.inverse_transform(all_data.reshape(all_data.size,1)))\n",
        "\n",
        "fig, (ax1) = plt.subplots(1, 1,figsize=(10,5), sharex=True, sharey=True)\n",
        "fig.suptitle(f'Prediction plot epoch {epoch_num}')\n",
        "for i,C in enumerate(D):\n",
        "  d_denorm = np.round(scaler.inverse_transform(C.reshape(C.size,1)))\n",
        "  ax1.plot(d_denorm, label=f'predict {i+1}')\n",
        "ax1.axvline(input_step-1, ls='dashed', c='r')\n",
        "ax1.plot(all_data_denorm, label='true')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data_denorm = np.round(scaler.inverse_transform(all_data.reshape(all_data.size,1)))\n",
        "temp_1=None\n",
        "\n",
        "fig, (ax1) = plt.subplots(1, 1,figsize=(10,5), sharex=True, sharey=True)\n",
        "fig.suptitle(f'Prediction plot epoch {epoch_num}')\n",
        "for i,C in enumerate(D):\n",
        "  temp_1 = np.round(scaler.inverse_transform(C.reshape(C.size,1)))\n",
        "\n",
        "ax1.plot(temp_1, label=f'predict')\n",
        "ax1.axvline(input_step-1, ls='dashed', c='r')\n",
        "ax1.plot(all_data_denorm, label='true')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import savetxt\n",
        "savetxt('content/BAB 6/modelLain/Wind_trans_adam.csv', temp_1, delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAPE = []\n",
        "for ind, d in enumerate(D):\n",
        "    d_denorm = np.round(scaler.inverse_transform(d.reshape(d.size,1)))\n",
        "    print(f\"Error Pred {ind+1}\")\n",
        "    print(f\"MAPE\\t : {np.round(mean_absolute_percentage_error(all_data_denorm[input_step+ind:], d_denorm[input_step+ind:])*100,5)}\")\n",
        "    print(f\"MAE\\t : {np.round(mean_absolute_error(all_data_denorm[input_step+ind:], d_denorm[input_step+ind:]),5)}\")\n",
        "    print(f\"MSE\\t : {np.round(mean_squared_error(all_data_denorm[input_step+ind:], d_denorm[input_step+ind:]),5)}\")\n",
        "    print(f\"RMSE\\t : {np.round(np.sqrt(mean_squared_error(all_data_denorm[input_step+ind:], d_denorm[input_step+ind:])),5)}\\n\")\n",
        "    MAPE.append(np.round(mean_absolute_percentage_error(all_data_denorm[input_step+ind:], d_denorm[input_step+ind:])*100,5))\n",
        "print(\"Rata-rata MAPE \",np.round(np.mean(MAPE),5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raise TimeoutError(\"Stopped\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Biv2HNiffBI"
      },
      "source": [
        "## Learning Rate Range Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZTlPVllffBI"
      },
      "outputs": [],
      "source": [
        "lrrt_model = Transformer(device, d_model, in_dim, N_enc, N_dec, h_enc, h_dec, ff_hidnum, hid_pre, hid_post, dropout_pre, dropout_post, dropout_model, norm_first)\n",
        "lrrt_model=lrrt_model.to(device)\n",
        "state_before_train_lrrt=lrrt_model.state_dict().copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIbik_LkffBI",
        "outputId": "89661aad-b643-41db-e39e-1abad79972c3"
      },
      "outputs": [],
      "source": [
        "def find_lr(model, train_loader, criterion, optimizer, init_lr=1e-6, final_lr=1e-1, num_epochs=100):\n",
        "    device = next(model.parameters()).device\n",
        "    lrs = np.logspace(np.log10(init_lr), np.log10(final_lr), num=num_epochs)\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        current_lr = lrs[epoch]\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = current_lr\n",
        "            print(param_group['lr'])\n",
        "\n",
        "        for iter, (x, y, tgt) in enumerate(train_loader):\n",
        "            x, y, tgt = x.to(device), y.to(device), tgt.to(device)\n",
        "            tgt = tgt[:,:,0]\n",
        "\n",
        "            out = model(x, y)\n",
        "            loss = criterion(out, tgt)\n",
        "            out_npy = out.to('cpu').detach().numpy().copy()\n",
        "            tgt_npy = tgt.to('cpu').detach().numpy().copy()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        val_loss = check_data(device, val_loader, model, criterion)\n",
        "        val_losses.append(val_loss)# MSE\n",
        "        losses.append(loss.item())\n",
        "        print(\"epoch {} losses {}\".format(epoch,loss.item()))\n",
        "\n",
        "    return lrs, losses,val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntGjDrQCffBJ",
        "outputId": "30a4bca1-b2c9-44a4-dc69-b4499e989260"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(lrrt_model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "learning_rates, losses,val_losses = find_lr(lrrt_model, train_loader, criterion, optimizer)\n",
        "fix_seed(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loss_np = np.array(losses)\n",
        "val_loss_np = np.array(val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yzdg45n4ffBJ",
        "outputId": "508deb69-08e5-4d4b-a386-91793106ec01"
      },
      "outputs": [],
      "source": [
        "# Simpan nilai learning rate dengan loss terkecil menggunakan MAE\n",
        "fig, ax = plt.subplots(figsize=(7,4))\n",
        "ax.plot(train_loss_np, label=\"train\")\n",
        "ax.plot(val_loss_np, label=\"validation\")\n",
        "best_lr = learning_rates[np.argmin(losses)]\n",
        "best_epoch = np.argmin(losses)\n",
        "best_loss = np.min(losses)\n",
        "print(f\"Learning rate terbaik: {best_lr}, pada epoch {best_epoch} dengan loss {best_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--1LVbHOBSIy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {
        "id": "xfsVgtLGSXUv"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, num_classes, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = Variable(torch.zeros(\n",
        "            self.num_layers, x.size(0), self.hidden_size))\n",
        "\n",
        "        c_0 = Variable(torch.zeros(\n",
        "            self.num_layers, x.size(0), self.hidden_size))\n",
        "\n",
        "        # Propagate input through LSTM\n",
        "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
        "\n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "\n",
        "        out = self.fc(h_out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NabsV8O5BBd5"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {
        "id": "sE7wChRlARDW"
      },
      "outputs": [],
      "source": [
        "# data_path = 'https://data.covid19.go.id/public/api/update.json'\n",
        "# data_path = 'update_22-3-2022.json'\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def load_data(data_path, from_api=True, dataset_len=None):\n",
        "    # data = requests.get(data_path).json() if from_api else pd.read_json(data_path)\n",
        "\n",
        "    # df = pd.DataFrame(data['update']['harian'])[['key','jumlah_positif']]\n",
        "    # df.key = pd.to_datetime(df.key, unit='ms')\n",
        "\n",
        "    # for i, row in enumerate(df.jumlah_positif):\n",
        "    #     df.loc[i,['jumlah_positif']] = row.get('value')\n",
        "\n",
        "    data=pd.read_csv(data_path)\n",
        "    df=data[[\"V1\",\"V2\"]]\n",
        "    df = df.set_index('V1')\n",
        "\n",
        "    # data=pd.read_csv(data_path)\n",
        "    # df=data[[\"date\",\"OT\"]]\n",
        "    # df = df.set_index('date')\n",
        "\n",
        "    # data=pd.read_csv(data_path)\n",
        "    # data = data.rename(columns={data.columns[0]: 'Date'}) \n",
        "    # data=data.dropna(subset=[\"ActivePower\"])\n",
        "    # # data=data[[\"Date\",\"ActivePower\",\"WindSpeed\"]]\n",
        "    # df=data[[\"Date\",\"ActivePower\"]]\n",
        "    # df = df.set_index('Date')\n",
        "\n",
        "    # df = df.set_index('key')\n",
        "    data_len = df.shape[0]\n",
        "    numpy_use = df.to_numpy() if dataset_len == None else df[:dataset_len].to_numpy()\n",
        "\n",
        "    return numpy_use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 434,
      "metadata": {
        "id": "RwQF4Y85-Hpn",
        "outputId": "b6f0ced5-9878-496a-b0cc-6c33aa5d57dd"
      },
      "outputs": [],
      "source": [
        "# data = load_data('update 12-05-2022.json', from_api=False, dataset_len=750)\n",
        "data = load_data('Data/m4/Daily-train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6MEnfZ3-70K",
        "outputId": "30d509eb-9636-4497-affa-1c35bbd146a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4227"
            ]
          },
          "execution_count": 435,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 436,
      "metadata": {
        "id": "vIWvJCpOVmwU"
      },
      "outputs": [],
      "source": [
        "def sliding_windows(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)\n",
        "\n",
        "sc = MinMaxScaler(feature_range=(-1, 1))\n",
        "training_data = sc.fit_transform(data)\n",
        "\n",
        "seq_length = 7\n",
        "x, y = sliding_windows(training_data, seq_length)\n",
        "\n",
        "test_size = 120\n",
        "train_size = int(len(y) - test_size)\n",
        "\n",
        "dataX = Variable(torch.Tensor(np.array(x)))\n",
        "dataY = Variable(torch.Tensor(np.array(y)))\n",
        "\n",
        "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
        "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
        "\n",
        "\n",
        "\n",
        "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
        "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdzFI5GJBUF5"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2vvHeFgVtCp",
        "outputId": "61cbc6ca-f3c7-4b53-f3fa-7d2e8964b636"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "input_size = 1\n",
        "hidden_size = 16\n",
        "num_layers = 1\n",
        "\n",
        "num_classes = 1\n",
        "loader = data.DataLoader(data.TensorDataset(trainX, trainY), shuffle=True, batch_size=1378)\n",
        "\n",
        "lstm = LSTM(input_size, num_classes, hidden_size, num_layers)\n",
        "# lstm = lstm.to(device)\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate, betas=(0.9,0.98))\n",
        "\n",
        "\n",
        "base_lr=0.0002782559402207126\n",
        "max_lr_multiplier=7\n",
        "cycle_size=15\n",
        "\n",
        "# hidden = None\n",
        "# scheduler = CosineCyclicLR(optimizer, base_lr=base_lr,max_lr=(base_lr*max_lr_multiplier), step_size=cycle_size)\n",
        "# scheduler = AutoCyclicLR(optimizer, base_lr=base_lr, max_lr=(base_lr*max_lr_multiplier), step_size=cycle_size)\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    # print(trainX.shape)\n",
        "    # outputs, hidden = rnn(trainX, hidden)\n",
        "    for X_batch, y_batch in loader:\n",
        "        # X_batch,y_batch=X_batch.to(device),y_batch.to(device)\n",
        "        y_pred = lstm(X_batch)\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        # scheduler.set_batch_data(X_batch) \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35ndYIwIKteS"
      },
      "source": [
        "## Testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 443,
      "metadata": {
        "id": "CKEzO1jzKydL"
      },
      "outputs": [],
      "source": [
        "lstm.eval()\n",
        "train_predict = lstm(testX)\n",
        "\n",
        "data_predict = train_predict.data.numpy()\n",
        "dataY_plot = testY.data.numpy()\n",
        "\n",
        "data_predict = np.round(sc.inverse_transform(data_predict))\n",
        "np.savetxt('data_predict.csv', data_predict, delimiter=',')\n",
        "\n",
        "dataY_plot = np.round(sc.inverse_transform(dataY_plot))\n",
        "np.savetxt('dataY_plot.csv', dataY_plot, delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "19_mmG2FXYPJ",
        "outputId": "dd787174-19bc-4bfb-b163-e8b3ab52c31d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7,3))\n",
        "ax.plot(dataY_plot, label=\"true\", linewidth=1.25)\n",
        "ax.plot(data_predict, label=\"LSTM\", linewidth=0.9)\n",
        "# df_label=pd.read_csv(\"data/m4/Daily-train.csv\")\n",
        "# interval=500\n",
        "\n",
        "# df=data[[\"V1\"]]\n",
        "# df = df.set_index('V1')\n",
        "# plt.xticks([x for items in df])\n",
        "# plt.xticks(df_label['V1'][::interval])\n",
        "plt.title(\"LSTM predict vs true\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import savetxt\n",
        "savetxt('content/BAB 6/modelLain/WIND_Lstm_BatchVar.csv', data_predict, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XcfqKK4FN9h"
      },
      "source": [
        "## Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F22fB6krDmWy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iCKnznRFPSO",
        "outputId": "0987e114-80c8-4a58-cf3a-8ceb01da73b9"
      },
      "outputs": [],
      "source": [
        "print(f\"Error Pred\")\n",
        "print(f\"MAPE\\t : {mean_absolute_percentage_error(data_predict, dataY_plot)*100}\")\n",
        "print(f\"MAE\\t : {mean_absolute_error(data_predict, dataY_plot)}\")\n",
        "print(f\"MSE\\t : {mean_squared_error(data_predict, dataY_plot)}\")\n",
        "print(f\"RMSE\\t : {np.sqrt(mean_squared_error(data_predict, dataY_plot))}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raise TimeoutError(\"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZKmgYgBoEt2"
      },
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olQP4qKEoEt2"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 444,
      "metadata": {
        "id": "BKsBUWM1oEt2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKX7w5NRoEt3"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 445,
      "metadata": {
        "id": "ZqM67N9lt1Hm"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim,  hidden_dim, layer_dim):\n",
        "        super(RNN, self).__init__()\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # Building your RNN\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, input_dim)\n",
        "        # batch_dim = number of samples per batch\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
        "\n",
        "        # Readout layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        # (layer_dim, batch_size, hidden_dim)\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # We need to detach the hidden state to prevent exploding/vanishing gradients\n",
        "        # This is part of truncated backpropagation through time (BPTT)\n",
        "        out, hn = self.rnn(x, h0.detach())\n",
        "\n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 100, 28, 10\n",
        "        # out[:, -1, :] --> 100, 10 --> just want last time step hidden states!\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        # out.size() --> 100, 10\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4IbeWUNoEt3"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 522,
      "metadata": {
        "id": "rkeq88F0oEt3"
      },
      "outputs": [],
      "source": [
        "# data_path = 'https://data.covid19.go.id/public/api/update.json'\n",
        "# data_path = 'update_22-3-2022.json'\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def load_data(data_path, from_api=True, dataset_len=None):\n",
        "    # data = requests.get(data_path).json() if from_api else pd.read_json(data_path)\n",
        "\n",
        "    # df = pd.DataFrame(data['update']['harian'])[['key','jumlah_positif']]\n",
        "    # df.key = pd.to_datetime(df.key, unit='ms')\n",
        "\n",
        "    # for i, row in enumerate(df.jumlah_positif):\n",
        "    #     df.loc[i,['jumlah_positif']] = row.get('value')\n",
        "    # data=pd.read_csv(data_path)\n",
        "    # df=data[[\"V1\",\"V2\"]]\n",
        "    # df = df.set_index('V1')\n",
        "\n",
        "    data=pd.read_csv(data_path)\n",
        "    df=data[[\"date\",\"OT\"]]\n",
        "    df = df.set_index('date')\n",
        "\n",
        "    # data=pd.read_csv(data_path)\n",
        "    # data = data.rename(columns={data.columns[0]: 'Date'}) \n",
        "    # data=data.dropna(subset=[\"ActivePower\"])\n",
        "    # # data=data[[\"Date\",\"ActivePower\",\"WindSpeed\"]]\n",
        "    # df=data[[\"Date\",\"ActivePower\"]]\n",
        "    # df = df.set_index('Date')\n",
        "    \n",
        "    # df = df.set_index('key')\n",
        "    data_len = df.shape[0]\n",
        "    numpy_use = df.to_numpy() if dataset_len == None else df[:dataset_len].to_numpy()\n",
        "\n",
        "    return numpy_use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 523,
      "metadata": {
        "id": "jWZaMmr6oEt3"
      },
      "outputs": [],
      "source": [
        "# data = load_data('update 12-05-2022.json', from_api=False, dataset_len=750)\n",
        "data = load_data('data/ETTm2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtzYhNjuoEt3",
        "outputId": "355d3f14-cdc3-4688-93de-c432c55204e0"
      },
      "outputs": [],
      "source": [
        "data.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 525,
      "metadata": {
        "id": "H_wgexu1oEt4"
      },
      "outputs": [],
      "source": [
        "def sliding_windows(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)\n",
        "\n",
        "sc = MinMaxScaler(feature_range=(-1, 1))\n",
        "training_data = sc.fit_transform(data)\n",
        "\n",
        "seq_length = 7\n",
        "x, y = sliding_windows(training_data, seq_length)\n",
        "\n",
        "test_size = 120\n",
        "train_size = int(len(y) - test_size)\n",
        "\n",
        "dataX = Variable(torch.Tensor(np.array(x)))\n",
        "dataY = Variable(torch.Tensor(np.array(y)))\n",
        "\n",
        "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
        "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
        "\n",
        "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
        "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGebfEF6oEt4"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDYxjbSSoEt4",
        "outputId": "a06706c6-2b13-4eb6-deaa-f4825ac191f8"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data\n",
        "num_epochs = 1\n",
        "learning_rate = 0.0002782559402207126\n",
        "\n",
        "input_size = 1\n",
        "hidden_size = 16\n",
        "num_layers = 1\n",
        "\n",
        "num_classes = 1\n",
        "\n",
        "rnn = RNN(input_size, num_classes, hidden_size, num_layers)\n",
        "\n",
        "loader = data.DataLoader(data.TensorDataset(trainX, trainY), shuffle=True, batch_size=67)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate, betas=(0.9,0.98))\n",
        "\n",
        "# hidden = None\n",
        "\n",
        "base_lr=0.0002782559402207126\n",
        "max_lr_multiplier=8\n",
        "cycle_size=15\n",
        "\n",
        "scheduler = AutoCyclicLR(optimizer, base_lr=base_lr,max_lr=(base_lr*max_lr_multiplier), step_size=cycle_size)\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    # print(trainX.shape)\n",
        "    # outputs, hidden = rnn(trainX, hidden)\n",
        "    for X_batch, y_batch in loader:\n",
        "        y_pred = rnn(X_batch)\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        scheduler.set_batch_data(X_batch) \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    \n",
        "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzBLK0lHoEt4"
      },
      "source": [
        "## Testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 528,
      "metadata": {
        "id": "jsq0gJxUoEt4"
      },
      "outputs": [],
      "source": [
        "rnn.eval()\n",
        "train_predict = rnn(testX)\n",
        "\n",
        "data_predict = train_predict.data.numpy()\n",
        "dataY_plot = testY.data.numpy()\n",
        "\n",
        "data_predict = np.round(sc.inverse_transform(data_predict))\n",
        "np.savetxt('data_predict.csv', data_predict, delimiter=',')\n",
        "\n",
        "dataY_plot = np.round(sc.inverse_transform(dataY_plot))\n",
        "np.savetxt('dataY_plot.csv', dataY_plot, delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 529,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataY_plot = testY.data.numpy()\n",
        "dataY_plot = np.round(sc.inverse_transform(dataY_plot))\n",
        "np.savetxt('dataY_plot.csv', dataY_plot, delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 530,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import loadtxt\n",
        "# m4_uni=loadtxt(\"content/BAB 6/multi/M4_1.csv\")\n",
        "m4_uni=loadtxt(\"content/BAB 6/modelLain/ETT_trans_cyclic.csv\")\n",
        "m4_LSTM=loadtxt(\"content/BAB 6/modelLain/ETT_lstm_batchVar.csv\")\n",
        "m4_RNN=loadtxt(\"content/BAB 6/modelLain/ETT_rnn_Adam.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f8mCiTzoEt5",
        "outputId": "9290ca0d-2a70-47ba-aea9-38c80fc32137"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "ax.plot(dataY_plot, label=\"True\", linewidth=1)\n",
        "# ax.plot(data_predict, \"r\",label=\"RNN\", linewidth=0.9)\n",
        "# plt.xticks(np.arange(0,61,4),[d.strftime('%Y-%m-%d') for d in pd.date_range('2022-01-21', periods=16, freq='4D')], rotation=45)\n",
        "# plt.title(\"RNN predict vs true\")\n",
        "plt.ylabel(\"Oil Temperature\")\n",
        "\n",
        "plt.xlabel(\"Timestamp\")\n",
        "plt.legend()\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.07),\n",
        "          ncol=1, fancybox=True, shadow=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import savetxt\n",
        "savetxt('content/BAB 6/modelLain/WIND_rnn_BatchVar.csv', data_predict, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mIk-3DqoEt5"
      },
      "source": [
        "## Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-US7z6GoEt5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcf4PDSsoEt5",
        "outputId": "29ab1342-4fe2-48b2-a882-8de7fae4bc92"
      },
      "outputs": [],
      "source": [
        "print(f\"Error Pred\")\n",
        "print(f\"MAPE\\t : {mean_absolute_percentage_error(data_predict, dataY_plot)*100}\")\n",
        "print(f\"MAE\\t : {mean_absolute_error(data_predict, dataY_plot)}\")\n",
        "print(f\"MSE\\t : {mean_squared_error(data_predict, dataY_plot)}\")\n",
        "print(f\"RMSE\\t : {np.sqrt(mean_squared_error(data_predict, dataY_plot))}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
